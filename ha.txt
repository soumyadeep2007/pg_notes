HA, load balancing and replication, backup and restore:

* Backup strategies: - SQL dump and restore

	- File system level backup

	- Continuous archiving

* File system level backup
	- tar up the data dir?
		-- worse than SQL dump. why?
			server needs to be brought down (buffering in the server and also the server
			needs to be shut down if we want to restore)

		-- lose capability of doing more granular backup/restore..pg_wal has no
		-- filtering capacity. So this method will only work for a full backup.

	- Consistent snapshot of the data dir.
		0. (Optional) CHECKPOINT;

		1. Use file-system feature to make "frozen snapshot" of the volume
		containing the database.

		2. Then copy over the datadir from that snapshot to a backup device.

		3. Release the frozen snapshot.

		-- No server downtime is required.

		-- Caveats: the datadir state captured like this will point to a state where
			the server was still up. If we try to bring the server back up in this
			situation, the server will think that it had crashed before and will go
			into recovery and try to replay WAL. If we did step 0, then recovery time
			will be lesser.

		-- If the setup has tablespaces, which are on different file systems, taking
			1. is difficult as simultaneous snapshot may be very difficult. In this case,
			this strategy IS NOT GOOD!!
			--- There is a workaround: shutdown the server and
			after a significant time period, take all of the frozen snapshots.
			OR 
			--- Enable continuous archiving only for the duration of 1-4. and then restore
			using continuous archive recovery.

	- Use rsync
		1. rsync while live

		2. Shutdown server

		3. rsync --checksum

* Continuous archiving and PITR:

	- Third strategy for backups: File-system
	level backup (base backup) + continuous backup of WAL files

	- Advantages: 
		-- We can start with a inconsistent file system as the starting
			point. We can just do with a tar, we don't need a consistent snapshot.
			--- Inconsistencies can be resolved after WAL replay.

		-- For large databases, where taking full backups is expensive, "continuous
			backup" can be achieved by continuously archiving the WAL files.

		-- It is not necessary to replay the WAL all the way, we could stop at any
			point and we will have a consistent snapshot of the database. It is
			possible to PITR to any point since the last base backup (since we have
			all the WAL since the last base backup).

			Instead of continuously archiving the WAL files, we could stream the WAL
			files over to another server that was borne out of the same base backup. The
			result is a warm standby.

	- WAL archiving setup: -- WAL records are grouped into segment files (of
			16MB, but can be configured).

		-- Segment names are numerical and are recycled (only if we are not using
			WAL archiving).

		-- postgresql.conf 

			--- wal_level >= replica

			--- archive_mode = on

			--- archive_command = <shell command to copy over the WAL segments
				wherever> 
				> e.g. archive_command = 'test ! -f /mnt/server/archivedir/%f && cp
					%p /mnt/server/archivedir/%f' 
					(%p= <path_to_file>, %f = <file_name>).

				> e.g. substitution: 
				test ! -f /mnt/server/archivedir/00000001000000A900000065 
				&& cp pg_wal/00000001000000A900000065 /mnt/server/archivedir/00000001000000A900000065

		-- Setup has to be calibrated well enough to ensure the failure case for WAL
			archiving is handled well (what if archive command fails because of the
			destination? -> pg_wal will continue to build until the disk is full, in
			which case Postgres will perform a PANIC shutdown).

		-- It is important to have the right security for the WAL archive.

		-- One MUST keep in mind that restoring from a WAL archive will apply all
			possible changes EXCEPT CHANGES TO conf files such postgresql.conf!!!
			These changes ARE NOT WALed.

		-- The archive_command is invoked only when a WAL segment becomes full!
			That means that there can be a a long delay between the completion
			of a transaction and it's safe recording in archive storage.

			But wait..what if the server does not generate 16MB of WAL?? ->
			What we have to do then is configure archive_timeout to perform a
			"segment file switch" to a new file, making the old file a candidate
			for archiving.
			Now, the old file will still be sized at 16MB!!!!!! (this means that
			setting a small archive_timeout will lead to WAL bloat!!!!)

			Note: a WAL file switch can also be perfomed by explicitly calling
			pg_switch_wal().

			Also one may provide a script for the archive_command. For eg, one
			may want to batch WAL files together before sending them over.

		-- One can pause archival temporarily by overriding archive_command to ''.
			This will cause backup of wal files in pg_wal of course.

		-- archive_cleanup_command can be specified to periodically clean up WAL
			segments that may have aged. It can be anything. For a single standby
			mode, we can make do with pg_archivecleanup.


	- Taking a base backup
		-- Use tar mode or non-tar mode (tar -> extract to dir)

		-- Use binary or sql API + tar(needs lots of orchestration, but allows)
			for a lot more fine grained control.

		-- To make use of a base backup, one needs access to the WAL segments
			generated during and after the pg_basebackup invocation. To help us
			out, pg_basebackup generates a backup_history file that is named as
			follows: If the starting WAL file is 0000000100001234000055CD,
			history file name: 0000000100001234000055CD.007C9330.backup

			After we make copies of these, all WAL segments < than the name of
			the backup file can be deleted.

		-- Each backup has a label to uniquely identify it.

	- Recovering using a continuous archive backup [can be used to perform
		a targeted or continuous recovery (standby mode)]:
		Steps for a targeted recovery:

		1. Stop the server if its running

		2. At least make a copy of the server's pg_wal dir. It may contain logs
			that have not been archived since the server went down.

		3. Clean datadir and under tablespace roots.

		4. Restore the files from backup (make sure the files have the right permissions)
			and make sure pg_tblspc contains the correct links.

		5. Nuke the new pg_wal dir (as it represents old wal of the server taken
			during the earlier base backup) and replace it with a new one with
			the correct permissions.

		6. Copy the files from step 2 to this new pg_wal dir.

		7. Setup recovery settings (GUCs such as restore_command and recovery
			target to indicate how to recover and how much to recover.. Typically,
			the restore command is a cp command with a special format..described
			below)
			Also, create recovery.signal in datadir. (Create a standby.signal
			if we wanted the recovering server to stay as a standby at the end
			of recovery..i.e. continuous recovery from the archive)

		8. Prevent users from connecting to the database while the database is
			recovering by temporarily updating pg_hba.conf

		9. Start the server. The server will read through the archived WAL and
			then the unarchived WAL from 6. Upon completion, the server itself
			will remove recovery.conf and then normal database operation will
			commence. If the recovery is halted at any time or there are any
			crashes, the recovery process can simply be restarted (recovery
			progress is tracked via updates made by the server to pg_control).

		10. Sanity check contents of database. If check doesn't pass go to 1.

	- Notion of timelines (to support arbitrary PITR):

		T1:	........[drop table]........
			        ^
			        (Wed 5:15PM)
			       ^
			       restore point
			       (Wed 5:14PM)
		T2:	       *********************

		-- If we want to be able to PITR and back, then we need timelines, otherwise 
			the WAL will be overwritten. 
		
		-- The timeline ID number is part of WAL segment file names so a new 
			timeline does not overwrite the WAL data generated by previous timelines.

		-- Every time a new timeline is created, PostgreSQL creates a “timeline 
			history” file that shows which timeline it branched off from and when. 

		-- While recovering an explicit timeline can be specified using recovery_target_timeline.

	- full_page_writes

	- WAL archives are often compressed to save space


* Primary/master - server having r/w capabilities

* Secondary/standby - server having only r capability - warm standby: server
can't answer queries until it is promoted - hot standby: server can answer r/o
queries

* Sync solution: Tx is not considered committed and changes not reflected on
any server, untill all of the servers have applied the changes. No standby
can fall behind.

* Solution can not only be deployment level but also database level or even,
table level.

* Log shipping standbys setup:

	- Primary operates in continuous archiving mode.

	- Replica operates in continuous recovery mode.

	- File based log shipping:
		-- MTU: 1 log segment (1 log file) ~ 16MB

	- Streaming replication:

	- Record based log shipping:
		-- MTU: 

	- Log shipping is async..there exists a window for loss, i.e. primary goes
		down and the unshipped WAL is lost. 
		-- Size of data loss window regulated by the archive_timeout GUC.

		-- Streaming replication is a technique to lower the window considerably.

	- Constraint: All servers should be running the same version of Postgres.


	- Standby server operation: 
		-- archive-based replication: can read wal directly from a WAL archive
			(GUC: restore_command) 
			--- restore command: shell command with special syntax to retrieve an
				archived wal segment. e.g. 'cp /mnt/server/archivedir/%f "%p"'
				// %p->dest dir, %f->file from archive

		-- or can read wal directly from the master over a TCP connection. //streaming replication

		-- standby will also play anything in its own pg_wal directory.
			There can be stuff in that directory, especially if the standby went down while there was
			stuff shipped from the master but not replayed yet.

		-- Standby order of ops:
			1. Restore all WAL available in archive location using "restore_command".

			2. Once 1. is done (restore_command will fail if there are no files left),
				restore any files from its pg_wal dir.

			3. Once 2. is done, and streaming replication is set up, standby will
				connect to the primary (using primary_conninfo) and will start
				streaming WAL from the last valid record
				it found in step 1. or step 2.

			4. If step 3. fails, go back to step 1.

			This loop can be broken if:
			i) Server stops.

			ii) Failover triggered by a trigger file or by "pg_ctl promote".

	- Master server prep: 
		-- We need to setup the master for continuous archiving as
			described before.

		-- The archive location MUST be accessible from the primary!!! (optional
			for a flavor of streaming replication)

		-- For streaming replication, pg_hba.conf and roles need to be setup to
			allow replication connections from the standby(s).

		-- max_wal_senders need to be high enough to support multiple standbys

	- Standby server prep:
		-- Restore the base backup of the primary.

		-- Create a standby.signal file in the standby's datadir

		-- Specify a restore_command to fetch WAL from the WAL archive.

		-- For multiple standbys, we have to set up the recovery_target_timeline.

		-- To use streaming replication, we must specify primary_conninfo.

		-- Set up continuous archiving as described above, for the rainy day when
			the standby will be promoted.

	- Streaming replication:
		-- Standby stays more up-to-date than with log-shipping.

		-- It is async by default!!! => lag b/w tx commit and changes on standby

		-- If used w/o file-based continuous archiving, the server might recycle
			old WAL segments before the standby gets a chance to receive them!
			
			There is the workaround by keeping "wal_keep_segments" high OR by
			configuring a replication slot for the standby.
			
			If the WAL archive is indeed accessible from the standby, then we don't
			need replication slots or the other workaround.

		-- Start with a file-based log shipping standby server and if we add
			the primary_conninfo GUC, and some auth stuff on the primary side, we
			end up with a streaming replication setup!!

		--  tcp_keepalives_idle, tcp_keepalives_interval and tcp_keepalives_count
			help the primary promptly notice a broken connection.

		-- Note: streaming replication will only start over the primary conn once
			the standby has replayed all outstanding WAL in the archive.

		-- Authentication setup....

		-- Monitoring:
			--- Replay lag and such can be calculated from pg_stat_replication.

			--- pg_current_lsn, sent_lsn, write_lsn, flush_lsn, replay_lsn etc.

	- Replication slots:
		-- Automation to ensure master does NOT remove any WAL that hasn't been
			sent to the standbys.

		-- Alternatives to replication slots:
			--- wal_keep_segments high enough.

			--- Continuous archival of WAL.

		-- Can lead to unbounded pg_wal sizes on the primary if replication slots
			are used, as opposed to the alternatives above.

		-- pg_replication_slots

		-- Cascading replication: master -> standby (C) -> standby.

			--- Minimizes connectivity to the master.

	- Sync rep for streaming replication:
		-- Allows for confirmation to a tx that all standbys have
			written/flushed/applied all WAL associated with the tx.

		-- synchronous_standby_names set and synchronous_commit = <write/apply...>
			synchronous_commit can be as granular as we want.

		-- May cause server shutdown to halt! (wal for an outstanding tx MUST be shipped)

		-- Multi-standby setup..setup can be elastic as well.

		-- Mode: streaming vs catchup
			--- When the standby connects to the primary for the first time, it
				will enter catchup mode and then it will transition over to
				streaming when it is caught up.

* Failover
	- When old primary restarts, we need to tell it that it is no longer the primary.

	- There needs to be some heartbeat mech to detect the connectivity b/w the two and viability of the primary or use a "witness server".

	- There is no mechanism to id a failure on the primary and notify the standby. Like what would happen to the IP address? (remember we have to do something about primary_conninfo)

	- To recover the old primary, 

* Archiver process (PG 12):
	- Forked from the postmaster

	- #define PGARCH_AUTOWAKE_INTERVAL 60 /* How often to force a poll of the
									 * archive status directory; in seconds. */
	  #define PGARCH_RESTART_INTERVAL 10	/* How often to attempt to restart a
									 * failed archiver; in seconds. */
	- /*
	   * Maximum number of retries allowed when attempting to archive a WAL
	   * file.
	   */
	  #define NUM_ARCHIVE_RETRIES 3

	- /*
	   * Maximum number of retries allowed when attempting to remove an
	   * orphan archive status file.
	   */
	  #define NUM_ORPHAN_CLEANUP_RETRIES 3

	- Handles signals:
		pqsignal(SIGHUP, ArchSigHupHandler);
		pqsignal(SIGTERM, ArchSigTermHandler);
		pqsignal(SIGQUIT, pgarch_exit);
		pqsignal(SIGUSR1, pgarch_waken);
		pqsignal(SIGUSR2, pgarch_waken_stop);

	- pgarch_MainLoop()
	{
		do
		{
			/* signal handling */

			pgarch_ArchiverCopyLoop();

			/* sleep until signal forces a wakeup */
		} while(!time_to_stop()) // quit if told (SIGUSR2) or Postmaster death
	}

	- pgarch_ArchiverCopyLoop()
	{
		/*
		 * invoked when its time to wakeup, or on SIGUSR2 when we do one last
		 * archive cycle and exit.
		 */
		char		xlog[MAX_XFN_CHARS + 1];
		while (pgarch_readyXlog(xlog))
		{
			/* signal handling */

			/* remove orphaned .ready status files (otherwise chaos!) */

			if(pgarch_archiveXlog(xlog))
			{
				/* wal file successfully archived */
				pgarch_archiveDone(xlog); /* marks a .ready file as .done */
				pgstat_send_archiver(xlog, false);
			}
			else
			{
				// failure
				pgstat_send_archiver(xlog, true);
				if (++failures >= NUM_ARCHIVE_RETRIES)
				{
					...
					return;		/* give up archiving for now */
				}
				pg_usleep(1000000L); /* sleep a sec before retrying */
			}
		}
	}


	- pgarch_readyXlog() - Returns name of the oldest xlog file that has not yet
	been archived (oldest file that has an archive status of .ready in the
	archive_status dir)
		-- Returning the oldest is important because the older an xlog file gets,
		the more the probability of it becoming recycled. Besides, we want to
		preserve the sequence of WAL, to make replay logic easier on the other
		side.

		-- The oldest comparsion considers .history files as older than any
		other file except another .history file.

		-- The oldest comparison also accounts for timelines. This implies that
		older timelines are given precedence for archiving. This may or may not
		be ideal.


	- pgarch_archiveXlog(xlog)
	{
		/* '%' placeholder substitution in archive_command */

		/*
		 * Invoke system() to call archive command and react to status code.
		 *
		 * Note that if archive_command failed or was terminated by a signal,
		 * the archiver process is aborted. This is okay, since the postmaster
		 * can always respawn us.
		 * 
		 * Reacting to the status code also involves setting the ps display.
		 */
	}

* Startup recovery process (startup.c):
	- Forked from the postmaster

	- Handles signals:

		pqsignal(SIGHUP, StartupProcSigHupHandler); /* reload config file */
		pqsignal(SIGTERM, StartupProcShutdownHandler);	/* request shutdown */
		pqsignal(SIGQUIT, startupproc_quickdie);	/* hard crash time */
		pqsignal(SIGUSR1, StartupProcSigUsr1Handler);
		pqsignal(SIGUSR2, StartupProcTriggerHandler);

	- StartupXLOG() -- updates pg_control for easy restartability!
	{
		/* verify XLOG status by reading control file db state. */

		/*
		 * Incredibly neat: XLOG_REPLAY_DELAY
		 * allows attachment of a debugger!
		 */

		/* Determine recovery target by consulting control file. */

		/* 
		 * Check for presence of standby|recovery.signal and set globals:
		 * ArchiveRecoveryRequested: T if standby|recovery.signal were present
		 * StandbyModeRequested = T, if standby.signal was found, F otherwise
		 */
		readRecoverySignalFile();

		validateRecoveryParameters();

		if (read_backup_label(&checkPointLoc, &backupEndRequired,
					  &backupFromStandby))
	  	{
	  		/* Recovery will start from the ckpt listed in the backup_label file. */
	  	}
	  	else
	  	{
	  		/*
	  		 * Strategy: replay WAL in pg_wal first and then look at archive if
	  		 * archive recovery was requested (determined by looking at
	  		 * pg_control)..
	  		 */

	  		/* Recovery will start from the last valid checkpoint (pg_control).	*/
	  	}

	  	/* Sanity check that checkpoint record is in expected timeline. */

  		/* Rel cache invalidation */

  		/* Shared memory initialization */

			/* REDO */
		if (InRecovery)
		{
			/* This means that we have considered recovery as necessary. */

			/*
			 * Update control file to indicate that we have started recovery
			 * and our start location (checkpoint record)
		 	 *
			 * Also grab recovery target info, if any
			 */

			/* Nuke pg_stat* data */

			/* Delete backup_label if any (all it's data is now in pg_control) */

			CheckRequiredParameterValues(); // ensure GUC settings allow recovery

			/* Init for HS */
			if (ArchiveRecoveryRequested && EnableHotStandby)
			{
				/* 
				 * Backends won't be allowed until min recovery point is reached
				 * as specified in the control file and a recovery snapshot has
				 * been established from a running-xacts WAL record.
				 */
				 InitRecoveryTransactionEnvironment();

				 /* more startup.. */
			}

			/* Init shared variables (XLogCtl) for WAL progress tracking. */

			/*
			 * Let postmaster know that we have started redo, so it can start
			 * checkpointer, so that it can perform restart points.
			 */

			/*
			 * Check if we have already reached a consistent point.
			 * If yes, signal PM that it can start accepting connections while
			 * updating the control file.
			 *
			 * Note if we are in crash recovery, this will early exit, as in
			 * crash recovery all the WAL has to be played.
			 */
			CheckRecoveryConsistency();
		}

		/* Read next WAL record and start main recovery loop. *
		do
		{
			/* Handle interrupts */

			/* Pause WAL recovery if requested by a pg_wal_replay_pause() */

			/* If we have reached the recovery target, set reachedStopPoint */

			/*
			 * Switch current timeline if current record being replayed causes
			 * a switch (XLOG_CHECKPOINT_SHUTDOWN, XLOG_END_OF_RECOVERY).
			 */

		 	/* Replay WAL record */
			RmgrTable[record->xl_rmid].rm_redo(xlogreader);

			/* Update progress variables in XLogCtl */

			/* 
			 * If there was a timeline switch, clean up any xlog files from the
			 * older timeline in pg_wal. !!!!!
			 */
			RemoveNonParentXlogFiles(EndRecPtr, ThisTimeLineID);

			/* For ReadRecord details: see WaitForWALToBecomeAvailable()
			record = ReadRecord(xlogreader, InvalidXLogRecPtr, LOG, false);
		} while (record != NULL)

		if(reachedStopPoint)
		{
			/*
			 * Take recovery action: shutdown, pause, promote.
			 */

			/* cleanup */
		}

		ShutdownWalRcv();

	}

	- WaitForWALToBecomeAvailable()
	{
		
	}